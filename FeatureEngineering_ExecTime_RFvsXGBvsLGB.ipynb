{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-28T04:55:27.864249Z",
     "start_time": "2020-06-28T04:54:31.424877Z"
    }
   },
   "outputs": [],
   "source": [
    "# from rest_framework.response import Response\n",
    "# from rest_framework.views import APIView\n",
    "# from edge.stats.algorithms.filter1 import  filter\n",
    "# from edge.stats.spark_utils import read_file\n",
    "import json\n",
    "# from edge.stats.models import Filter\n",
    "# from edge.stats.db_update.col_map import colmap_swap,colmap_json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "from boruta import BorutaPy\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "import traceback\n",
    "# from django.db import connections\n",
    "# from edge.stats.db_update.ignore_check import get_unignored\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T02:58:27.450143Z",
     "start_time": "2020-06-29T02:58:26.970119Z"
    }
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "def feature_engineering_test (folder_path, csv_file_names) :\n",
    "    \n",
    "    extension = \".csv\"\n",
    "    data_summary = pd.DataFrame()\n",
    "    \n",
    "    df_empty = pd.DataFrame()\n",
    "    with pd.ExcelWriter('FeatureEngineering_ranking_stats.xlsx') as writer:\n",
    "        df_empty.to_excel(writer, sheet_name='10000KB_to_50000KB', index=False)\n",
    "    \n",
    "    with pd.ExcelWriter('FeatureEngineering_output_stats.xlsx') as writer:\n",
    "        df_empty.to_excel(writer, sheet_name='10000KB_to_50000KB', index=False)\n",
    "\n",
    "    for i in csv_file_names:\n",
    "        item = i\n",
    "        # 1 - Name of the dataset\n",
    "        file_name = item[0]\n",
    "        print('Start('+str(datetime.now())+'): '+file_name)\n",
    "        df = pd.read_csv(folder_path+file_name+extension, encoding='latin-1')\n",
    "        df_size_bytes = sys.getsizeof(df)\n",
    "        # 2 - Size(in MB) of the dataset\n",
    "        # df_size_mb = round(0.00000095367432 * df_size_bytes, 2)\n",
    "        df_size_mb = 0.00000095367432 * df_size_bytes\n",
    "        df_shape = df.shape\n",
    "        # 3 - Count of rows in the dataset\n",
    "        df_rows = df_shape[0]\n",
    "        # 4 - Count of columns in the dataset\n",
    "        df_columns = df_shape[1]\n",
    "        # 5 - Count of Numerical columns\n",
    "        df_dtypes = df.dtypes.value_counts()\n",
    "        num_dtypes = ['int64','float64','int32','float32']\n",
    "        num_cols = 0\n",
    "        for i in num_dtypes:\n",
    "            if df_dtypes.get(i) != None:\n",
    "                num_cols = num_cols + df_dtypes.get(i)\n",
    "        # 6 - Count of Categorical columns\n",
    "        cat_cols = df_columns - num_cols\n",
    "        # 7 - Count of Missing values\n",
    "        null_count = df.isnull().sum().sum()\n",
    "        # 8 - Target column\n",
    "        target_col = item[1]\n",
    "        # 9 - Target column datatype\n",
    "        target_dtype = df[target_col].dtype\n",
    "        # 10 - Count of distinct classes\n",
    "        target_classes = df[target_col].nunique()\n",
    "\n",
    "        def boruta(data, target):\n",
    "            target_type = data[target].dtype\n",
    "            target_nclasses = data[target].nunique()\n",
    "            class DataFrameImputer(TransformerMixin):\n",
    "                def __init__(self):\n",
    "                    \"\"\"Impute missing values.\n",
    "\n",
    "                    Columns of dtype object are imputed with the most frequent value\n",
    "                    in column.\n",
    "\n",
    "                    Columns of other types are imputed with mean of column.\n",
    "\n",
    "                    \"\"\"\n",
    "\n",
    "                def fit(self, X, y=None):\n",
    "                    self.fill = pd.Series([X[c].value_counts().index[0]\n",
    "                                           if X[c].dtype == np.dtype('O') else X[c].mean() for c in X],\n",
    "                                          index=X.columns)\n",
    "\n",
    "                    return self\n",
    "\n",
    "                def transform(self, X, y=None):\n",
    "                    return X.fillna(self.fill)\n",
    "\n",
    "            cat_data = data.select_dtypes(include=[\"object\"])\n",
    "            num_data = data.select_dtypes(include=[\"int64\", \"float64\",\"int32\",\"float32\"])\n",
    "            num_data = DataFrameImputer().fit_transform(num_data)\n",
    "            cat_data = DataFrameImputer().fit_transform(cat_data)\n",
    "\n",
    "            # Label encoding the values - Converting into Numerical\n",
    "            \"\"\" Some of the algorithms has hard constraint that it cannot process categorical data . For such algorithms,\n",
    "                User has to convert categorical features into Numeric. We have few techniques for this operation and \n",
    "                we are implementing the famous and good-result methods here as  \n",
    "                Label - Encoding \n",
    "            \"\"\"\n",
    "            # cat_data = cat_data.apply(LabelEncoder().fit_transform)\n",
    "            cat_data = cat_data.apply(lambda col: LabelEncoder().fit_transform(col.astype(str)))\n",
    "            if cat_data.empty==True:\n",
    "                data=num_data\n",
    "            else:\n",
    "                 data = pd.concat([num_data, cat_data], axis=1)\n",
    "            Y = data[target]\n",
    "            X = data.drop([target], axis=1)\n",
    "            x = X.as_matrix()\n",
    "            y = Y.as_matrix()\n",
    "            # x = X.values()\n",
    "            # y = Y.values()\n",
    "\n",
    "            # Create empty Multi-Index dataframe\n",
    "            tuples = []\n",
    "            index = pd.MultiIndex.from_tuples(tuples, names=['Model', 'Feature_rank'])\n",
    "            df_result = pd.DataFrame(columns=index)\n",
    "            model = None\n",
    "\n",
    "            if (target_type == 'object') and (target_nclasses <= 2):\n",
    "                model = 'Binary Classification'\n",
    "                import numpy.ma as ma\n",
    "                x = np.where(np.isnan(x), ma.array(x, mask=np.isnan(x)).mean(axis=0), x)\n",
    "                y = np.where(np.isnan(y), ma.array(y, mask=np.isnan(y)).mean(axis=0), y)\n",
    "\n",
    "\n",
    "                # 1 - Random Forest Classifier\n",
    "                start_rf = datetime.now()\n",
    "                rf_ = RandomForestClassifier(n_estimators=500, class_weight='balanced', max_depth=15)\n",
    "                feature_selection_rf = BorutaPy(rf_, n_estimators='auto', verbose=0)\n",
    "                feature_selection_rf.fit(x, y)\n",
    "                stop_rf = datetime.now()\n",
    "                execution_time_rf = stop_rf-start_rf\n",
    "                feature_df_rf = pd.DataFrame(X.columns.tolist())\n",
    "                feature_df_rf['rank'] = feature_selection_rf.ranking_\n",
    "                feature_df_rf = feature_df_rf.sort_values('rank', ascending=True).reset_index(drop=True)\n",
    "                feature_df_rf.columns = ['feature_name', 'Rank']\n",
    "                model_rf = 'Random Forest (Execution Time:'+str(execution_time_rf)+')'\n",
    "                df_result[model_rf, 'Feature'] = feature_df_rf.feature_name.tolist()\n",
    "                df_result[model_rf, 'Rank'] = feature_df_rf.Rank.tolist()\n",
    "\n",
    "                # 2 - XGB Classifier\n",
    "                start_xgb = datetime.now()\n",
    "                params_xgb = {'objective':'binary:logistic', 'num_boost_round':50, 'max_depth':10, 'learning_rate':0.1}\n",
    "                xgb_ = XGBClassifier(**params_xgb)\n",
    "                feature_selection_xgb = BorutaPy(xgb_, n_estimators='auto', verbose=0)\n",
    "                feature_selection_xgb.fit(x, y)\n",
    "                stop_xgb = datetime.now()\n",
    "                execution_time_xgb = stop_xgb-start_xgb\n",
    "                feature_df_xgb = pd.DataFrame(X.columns.tolist())\n",
    "                feature_df_xgb['rank'] = feature_selection_xgb.ranking_\n",
    "                feature_df_xgb = feature_df_xgb.sort_values('rank', ascending=True).reset_index(drop=True)\n",
    "                feature_df_xgb.columns = ['feature_name', 'Rank']\n",
    "                model_xgb = 'XGBoost (Execution Time:'+str(execution_time_xgb)+')'\n",
    "                df_result[model_xgb, 'Feature'] = feature_df_xgb.feature_name.tolist()\n",
    "                df_result[model_xgb, 'Rank'] = feature_df_xgb.Rank.tolist()\n",
    "\n",
    "                # 3 - LGBM Classifier\n",
    "                start_lgb = datetime.now()\n",
    "                params_lgb = {'objective':'binary', 'num_boost_round':50, 'max_depth':10, 'learning_rate':0.1, \n",
    "                              'class_weight':'balanced'}\n",
    "                lgb_ = LGBMClassifier(**params_lgb)\n",
    "                feature_selection_lgb = BorutaPy(lgb_, n_estimators='auto', verbose=0)\n",
    "                feature_selection_lgb.fit(x, y)\n",
    "                stop_lgb = datetime.now()\n",
    "                execution_time_lgb = stop_lgb-start_lgb\n",
    "                feature_df_lgb = pd.DataFrame(X.columns.tolist())\n",
    "                feature_df_lgb['rank'] = feature_selection_lgb.ranking_\n",
    "                feature_df_lgb = feature_df_lgb.sort_values('rank', ascending=True).reset_index(drop=True)\n",
    "                feature_df_lgb.columns = ['feature_name', 'Rank']\n",
    "                model_lgb = 'LGBoost (Execution Time:'+str(execution_time_lgb)+')'\n",
    "                df_result[model_lgb, 'Feature'] = feature_df_lgb.feature_name.tolist()\n",
    "                df_result[model_lgb, 'Rank'] = feature_df_lgb.Rank.tolist()\n",
    "            \n",
    "            elif (target_type == 'object') and (target_nclasses > 2):\n",
    "                model = 'Multiclass Classification'\n",
    "                import numpy.ma as ma\n",
    "                x = np.where(np.isnan(x), ma.array(x, mask=np.isnan(x)).mean(axis=0), x)\n",
    "                y = np.where(np.isnan(y), ma.array(y, mask=np.isnan(y)).mean(axis=0), y)\n",
    "\n",
    "\n",
    "                # 1 - Random Forest Classifier\n",
    "                start_rf = datetime.now()\n",
    "                rf_ = RandomForestClassifier(n_estimators=500, class_weight='balanced', max_depth=15)\n",
    "                feature_selection_rf = BorutaPy(rf_, n_estimators='auto', verbose=0)\n",
    "                feature_selection_rf.fit(x, y)\n",
    "                stop_rf = datetime.now()\n",
    "                execution_time_rf = stop_rf-start_rf\n",
    "                feature_df_rf = pd.DataFrame(X.columns.tolist())\n",
    "                feature_df_rf['rank'] = feature_selection_rf.ranking_\n",
    "                feature_df_rf = feature_df_rf.sort_values('rank', ascending=True).reset_index(drop=True)\n",
    "                feature_df_rf.columns = ['feature_name', 'Rank']\n",
    "                model_rf = 'Random Forest (Execution Time:'+str(execution_time_rf)+')'\n",
    "                df_result[model_rf, 'Feature'] = feature_df_rf.feature_name.tolist()\n",
    "                df_result[model_rf, 'Rank'] = feature_df_rf.Rank.tolist()\n",
    "\n",
    "                # 2 - XGB Classifier\n",
    "                start_xgb = datetime.now()\n",
    "                params_xgb = {'objective':'multi:softmax', 'num_boost_round':50, 'max_depth':10, 'learning_rate':0.1}\n",
    "                xgb_ = XGBClassifier(**params_xgb)\n",
    "                feature_selection_xgb = BorutaPy(xgb_, n_estimators='auto', verbose=0)\n",
    "                feature_selection_xgb.fit(x, y)\n",
    "                stop_xgb = datetime.now()\n",
    "                execution_time_xgb = stop_xgb-start_xgb\n",
    "                feature_df_xgb = pd.DataFrame(X.columns.tolist())\n",
    "                feature_df_xgb['rank'] = feature_selection_xgb.ranking_\n",
    "                feature_df_xgb = feature_df_xgb.sort_values('rank', ascending=True).reset_index(drop=True)\n",
    "                feature_df_xgb.columns = ['feature_name', 'Rank']\n",
    "                model_xgb = 'XGBoost (Execution Time:'+str(execution_time_xgb)+')'\n",
    "                df_result[model_xgb, 'Feature'] = feature_df_xgb.feature_name.tolist()\n",
    "                df_result[model_xgb, 'Rank'] = feature_df_xgb.Rank.tolist()\n",
    "\n",
    "                # 3 - LGBM Classifier\n",
    "                start_lgb = datetime.now()\n",
    "                params_lgb = {'objective':'multiclass', 'num_boost_round':50, 'max_depth':10, 'learning_rate':0.1, \n",
    "                              'class_weight':'balanced'}\n",
    "                lgb_ = LGBMClassifier(**params_lgb)\n",
    "                feature_selection_lgb = BorutaPy(lgb_, n_estimators='auto', verbose=0)\n",
    "                feature_selection_lgb.fit(x, y)\n",
    "                stop_lgb = datetime.now()\n",
    "                execution_time_lgb = stop_lgb-start_lgb\n",
    "                feature_df_lgb = pd.DataFrame(X.columns.tolist())\n",
    "                feature_df_lgb['rank'] = feature_selection_lgb.ranking_\n",
    "                feature_df_lgb = feature_df_lgb.sort_values('rank', ascending=True).reset_index(drop=True)\n",
    "                feature_df_lgb.columns = ['feature_name', 'Rank']\n",
    "                model_lgb = 'LGBoost (Execution Time:'+str(execution_time_lgb)+')'\n",
    "                df_result[model_lgb, 'Feature'] = feature_df_lgb.feature_name.tolist()\n",
    "                df_result[model_lgb, 'Rank'] = feature_df_lgb.Rank.tolist()\n",
    "\n",
    "            elif (target_type == 'int32') | (target_type == 'float32') | (target_type == 'float64') | (target_type == 'int64'):\n",
    "                model = 'Regression'\n",
    "                col_mean = np.nanmean(x, axis=0)\n",
    "                inds = np.where(np.isnan(x))\n",
    "                x[inds] = np.take(col_mean, inds[1])\n",
    "                inds = np.where(np.isinf(x))\n",
    "                x[inds] = np.take(col_mean, inds[1])\n",
    "                import numpy.ma as ma\n",
    "                x = np.where(np.isnan(x), ma.array(x, mask=np.isnan(x)).mean(axis=0), x)\n",
    "                y = np.where(np.isnan(y), ma.array(y, mask=np.isnan(y)).mean(axis=0), y)\n",
    "\n",
    "                # 1 - Random Forest Regressor\n",
    "                start_rf = datetime.now()\n",
    "                rf_ = RandomForestRegressor(n_estimators=500, max_depth=15)\n",
    "                feature_selection = BorutaPy(rf_, n_estimators='auto', verbose=0)\n",
    "                feature_selection.fit(x, y)\n",
    "                stop_rf = datetime.now()\n",
    "                execution_time_rf = stop_rf-start_rf\n",
    "                feature_df = pd.DataFrame(X.columns.tolist())\n",
    "                feature_df['rank'] = feature_selection.ranking_\n",
    "                feature_df = feature_df.sort_values('rank', ascending=True).reset_index(drop=True)\n",
    "                feature_df.columns = ['feature_name', 'Rank']\n",
    "                model_rf = 'Random Forest (Execution Time:'+str(execution_time_rf)+')'\n",
    "                df_result[model_rf, 'Feature'] = feature_df.feature_name.tolist()\n",
    "                df_result[model_rf, 'Rank'] = feature_df.Rank.tolist()\n",
    "\n",
    "                # 2 - XGB Regressor\n",
    "                start_xgb = datetime.now()\n",
    "                params_xgb = {'objective':'reg:squarederror', 'n_estimators':50, 'max_depth':10, 'learning_rate':0.1}\n",
    "                xgb_ = XGBRegressor(**params_xgb)\n",
    "                feature_selection_xgb = BorutaPy(xgb_, n_estimators='auto', verbose=0)\n",
    "                feature_selection_xgb.fit(x, y)\n",
    "                stop_xgb = datetime.now()\n",
    "                execution_time_xgb = stop_xgb-start_xgb\n",
    "                feature_df_xgb = pd.DataFrame(X.columns.tolist())\n",
    "                feature_df_xgb['rank'] = feature_selection_xgb.ranking_\n",
    "                feature_df_xgb = feature_df_xgb.sort_values('rank', ascending=True).reset_index(drop=True)\n",
    "                feature_df_xgb.columns = ['feature_name', 'Rank']\n",
    "                model_xgb = 'XGBoost (Execution Time:'+str(execution_time_xgb)+')'\n",
    "                df_result[model_xgb, 'Feature'] = feature_df_xgb.feature_name.tolist()\n",
    "                df_result[model_xgb, 'Rank'] = feature_df_xgb.Rank.tolist()\n",
    "\n",
    "                # 3 - LGBM Regressor\n",
    "                start_lgb = datetime.now()\n",
    "                params_lgb = {'objective':'regression', 'n_estimators':50, 'max_depth':10, 'learning_rate':0.1, \n",
    "                              'class_weight':'balanced'}\n",
    "                lgb_ = LGBMRegressor(**params_lgb)\n",
    "                feature_selection_lgb = BorutaPy(lgb_, n_estimators='auto', verbose=0)\n",
    "                feature_selection_lgb.fit(x, y)\n",
    "                stop_lgb = datetime.now()\n",
    "                execution_time_lgb = stop_lgb-start_lgb\n",
    "                feature_df_lgb = pd.DataFrame(X.columns.tolist())\n",
    "                feature_df_lgb['rank'] = feature_selection_lgb.ranking_\n",
    "                feature_df_lgb = feature_df_lgb.sort_values('rank', ascending=True).reset_index(drop=True)\n",
    "                feature_df_lgb.columns = ['feature_name', 'Rank']\n",
    "                model_lgb = 'LGBoost (Execution Time:'+str(execution_time_lgb)+')'\n",
    "                df_result[model_lgb, 'Feature'] = feature_df_lgb.feature_name.tolist()\n",
    "                df_result[model_lgb, 'Rank'] = feature_df_lgb.Rank.tolist()\n",
    "\n",
    "            # return feature_df.head(feature_selection.n_features_),feature_df,execution_time_rf\n",
    "            # return df_result\n",
    "            return model, execution_time_rf, execution_time_xgb, execution_time_lgb, df_result\n",
    "\n",
    "        model, execution_time_rf, execution_time_xgb, execution_time_lgb, df_result = boruta(data=df, target=target_col)\n",
    "\n",
    "        row_data = [[file_name, df_size_mb, df_rows, df_columns, cat_cols, num_cols, null_count, target_col, target_dtype, \n",
    "                    target_classes, model, execution_time_rf, execution_time_xgb, execution_time_lgb, \n",
    "                    str(execution_time_rf), str(execution_time_xgb), str(execution_time_lgb)], ]\n",
    "        df_2 = pd.DataFrame(row_data, columns=['Dataset','Size(MB)','#_Rows','#_Columns','#_Category_cols','#_Numerical_cols',\n",
    "                                               '#_Missing_values','Target_col','Target_dtype','#_Target_Unique_values',\n",
    "                                               'Model_type','ExecTime_RandomForest','ExecTime_XGBoost','ExecTime_LightGBM',\n",
    "                                               'str_ExecTime_RF','str_ExecTime_XGB','str_ExecTime_LGB'])\n",
    "        df_2['str_ET_RF'] = df_2['ExecTime_RandomForest'].apply(lambda x: str(x) if x!=None else x)\n",
    "        df_2['str_ET_XGB'] = df_2['ExecTime_XGBoost'].apply(lambda x: str(x) if x!=None else x)\n",
    "        df_2['str_ET_LGB'] = df_2['ExecTime_LightGBM'].apply(lambda x: str(x) if x!=None else x)\n",
    "        \n",
    "        data_summary = data_summary.append(df_2, ignore_index=True)\n",
    "        \n",
    "        with pd.ExcelWriter('FeatureEngineering_ranking_stats.xlsx', engine='openpyxl', mode='a') as writer:\n",
    "            df_result.to_excel(writer, sheet_name=file_name, index=True)\n",
    "        \n",
    "        with pd.ExcelWriter('FeatureEngineering_output_stats.xlsx', engine='openpyxl', mode='a') as writer:\n",
    "            data_summary.to_excel(writer, sheet_name=file_name, index=False)\n",
    "        print('End('+str(datetime.now())+'): '+file_name)\n",
    "    \n",
    "    return data_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-28T10:46:19.388874Z",
     "start_time": "2020-06-28T10:46:19.384875Z"
    }
   },
   "outputs": [],
   "source": [
    "folder_path = \"D:/Solverminds/Datasets/\"\n",
    "csv_file_names = [('Titanic','Survived'),('Loan','Loan_Status')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-28T10:46:52.269326Z",
     "start_time": "2020-06-28T10:46:19.992522Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start(2020-06-28 16:16:20.168519): Titanic\n",
      "End(2020-06-28 16:16:42.798640): Titanic\n",
      "Start(2020-06-28 16:16:42.798640): Loan\n",
      "End(2020-06-28 16:16:52.189331): Loan\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Size(MB)</th>\n",
       "      <th>#_Rows</th>\n",
       "      <th>#_Columns</th>\n",
       "      <th>#_Category_cols</th>\n",
       "      <th>#_Numerical_cols</th>\n",
       "      <th>#_Missing_values</th>\n",
       "      <th>Target_col</th>\n",
       "      <th>Target_dtype</th>\n",
       "      <th>#_Target_Unique_values</th>\n",
       "      <th>Model_type</th>\n",
       "      <th>ExecTime_RandomForest</th>\n",
       "      <th>ExecTime_XGBoost</th>\n",
       "      <th>ExecTime_LightGBM</th>\n",
       "      <th>str_ExecTime_RF</th>\n",
       "      <th>str_ExecTime_XGB</th>\n",
       "      <th>str_ExecTime_LGB</th>\n",
       "      <th>str_ET_RF</th>\n",
       "      <th>str_ET_XGB</th>\n",
       "      <th>str_ET_LGB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Titanic</td>\n",
       "      <td>0.311073</td>\n",
       "      <td>891</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>866</td>\n",
       "      <td>Survived</td>\n",
       "      <td>int64</td>\n",
       "      <td>2</td>\n",
       "      <td>Regression</td>\n",
       "      <td>00:00:02.608227</td>\n",
       "      <td>00:00:13.616966</td>\n",
       "      <td>00:00:06.124956</td>\n",
       "      <td>0:00:02.608227</td>\n",
       "      <td>0:00:13.616966</td>\n",
       "      <td>0:00:06.124956</td>\n",
       "      <td>0 days 00:00:02.608227</td>\n",
       "      <td>0 days 00:00:13.616966</td>\n",
       "      <td>0 days 00:00:06.124956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Loan</td>\n",
       "      <td>0.313653</td>\n",
       "      <td>614</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>149</td>\n",
       "      <td>Loan_Status</td>\n",
       "      <td>object</td>\n",
       "      <td>2</td>\n",
       "      <td>Binary Classification</td>\n",
       "      <td>00:00:03.890419</td>\n",
       "      <td>00:00:04.048261</td>\n",
       "      <td>00:00:01.060014</td>\n",
       "      <td>0:00:03.890419</td>\n",
       "      <td>0:00:04.048261</td>\n",
       "      <td>0:00:01.060014</td>\n",
       "      <td>0 days 00:00:03.890419</td>\n",
       "      <td>0 days 00:00:04.048261</td>\n",
       "      <td>0 days 00:00:01.060014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dataset  Size(MB)  #_Rows  #_Columns  #_Category_cols  #_Numerical_cols  \\\n",
       "0  Titanic  0.311073     891         12                7                 5   \n",
       "1     Loan  0.313653     614         13               12                 1   \n",
       "\n",
       "   #_Missing_values   Target_col Target_dtype  #_Target_Unique_values  \\\n",
       "0               866     Survived        int64                       2   \n",
       "1               149  Loan_Status       object                       2   \n",
       "\n",
       "              Model_type ExecTime_RandomForest ExecTime_XGBoost  \\\n",
       "0             Regression       00:00:02.608227  00:00:13.616966   \n",
       "1  Binary Classification       00:00:03.890419  00:00:04.048261   \n",
       "\n",
       "  ExecTime_LightGBM str_ExecTime_RF str_ExecTime_XGB str_ExecTime_LGB  \\\n",
       "0   00:00:06.124956  0:00:02.608227   0:00:13.616966   0:00:06.124956   \n",
       "1   00:00:01.060014  0:00:03.890419   0:00:04.048261   0:00:01.060014   \n",
       "\n",
       "                str_ET_RF              str_ET_XGB              str_ET_LGB  \n",
       "0  0 days 00:00:02.608227  0 days 00:00:13.616966  0 days 00:00:06.124956  \n",
       "1  0 days 00:00:03.890419  0 days 00:00:04.048261  0 days 00:00:01.060014  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stats = feature_engineering_test(folder_path=folder_path, csv_file_names=csv_file_names)\n",
    "df_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-28T05:25:44.923471Z",
     "start_time": "2020-06-28T05:25:44.907473Z"
    }
   },
   "outputs": [],
   "source": [
    "folder_path = \"D:/Solverminds/Datasets/\"\n",
    "csv_below_1000KB = [('NAN_file','diagnosis'),('recruiting_costs','Total'),('recruiting_costs','Employment Source'),\n",
    "                    ('fertility_Diagnosis','target'),('headbrain','Brain Weight(grams)'),('Adult','income'),('Iris','Species'),\n",
    "                    ('Blood_transfusion_Trn','Blood'),('Heart_disease_Prediction','heart_disease'),('wine_1','Proline'),\n",
    "                    ('Diabetes','Outcome'),('armenianpubs','Fav_Pub'),('production_staff','90-day Complaints'),\n",
    "                    ('ii_snapshot','resigned_rejoined'),('Loan','Loan_Status'),('CaystonFinalData','class'),\n",
    "                    ('patientdetail','Fatigue'),('Concrete_Data','Concrete compressive strength(MPa, megapascals) '),\n",
    "                    ('review','Score'),('Titanic','Survived'),('StorageAnalysistest','VslDelayBy'),('earthquake','depth'),\n",
    "                    ('core_dataset','Pay Rate'),('food_coded','weight'),('HR_Full','Pay Rate'),('patient','Status'),\n",
    "                    ('Rock_Mine','Rock_Mine'),('winequality-red','quality'),('Sacramento_realestate_transactions','price'),\n",
    "                    ('Cancer_Diagnostic','diagnosis'),('Detect_anomaly','count'),('Curr_test','sensex'),('soybean','class'),\n",
    "                    ('abalone_data','rings'),('Azdata','FamilyHistory'),('Missing_People','Gender'),('test_detect_anoms','count'),\n",
    "                    ('all','Bus.services'),('all','Drinking.water.facilities'),('mushrooms','class'),('PMS_TS','TITLE'),\n",
    "                    ('house','SalePrice'),('all_data_ii','resigned_rejoined'),('HR','salary'),('Mart_Sales','Item_Outlet_Sales'),\n",
    "                    ('CC_GENERAL','CREDIT_LIMIT')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-28T09:44:46.326822Z",
     "start_time": "2020-06-28T05:25:46.275848Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start(2020-06-28 10:55:46.379839): NAN_file\n",
      "End(2020-06-28 10:55:48.120704): NAN_file\n",
      "Start(2020-06-28 10:55:48.120704): recruiting_costs\n",
      "End(2020-06-28 10:55:52.781284): recruiting_costs\n",
      "Start(2020-06-28 10:55:52.781284): recruiting_costs\n",
      "End(2020-06-28 10:55:54.342298): recruiting_costs\n",
      "Start(2020-06-28 10:55:54.342298): fertility_Diagnosis\n",
      "End(2020-06-28 10:55:58.795311): fertility_Diagnosis\n",
      "Start(2020-06-28 10:55:58.795311): headbrain\n",
      "End(2020-06-28 10:55:59.635283): headbrain\n",
      "Start(2020-06-28 10:55:59.635283): Adult\n",
      "End(2020-06-28 10:56:01.756391): Adult\n",
      "Start(2020-06-28 10:56:01.756391): Iris\n",
      "End(2020-06-28 10:56:04.652667): Iris\n",
      "Start(2020-06-28 10:56:04.660632): Blood_transfusion_Trn\n",
      "End(2020-06-28 10:56:10.287158): Blood_transfusion_Trn\n",
      "Start(2020-06-28 10:56:10.287158): Heart_disease_Prediction\n",
      "End(2020-06-28 10:56:20.904482): Heart_disease_Prediction\n",
      "Start(2020-06-28 10:56:20.904482): wine_1\n",
      "End(2020-06-28 10:56:35.548043): wine_1\n",
      "Start(2020-06-28 10:56:35.548043): Diabetes\n",
      "End(2020-06-28 10:56:46.552837): Diabetes\n",
      "Start(2020-06-28 10:56:46.552837): armenianpubs\n",
      "End(2020-06-28 10:57:10.628412): armenianpubs\n",
      "Start(2020-06-28 10:57:10.628412): production_staff\n",
      "End(2020-06-28 10:57:20.330220): production_staff\n",
      "Start(2020-06-28 10:57:20.330220): ii_snapshot\n",
      "End(2020-06-28 10:57:32.166131): ii_snapshot\n",
      "Start(2020-06-28 10:57:32.166131): Loan\n",
      "End(2020-06-28 10:57:39.613647): Loan\n",
      "Start(2020-06-28 10:57:39.613647): CaystonFinalData\n",
      "End(2020-06-28 10:57:48.197143): CaystonFinalData\n",
      "Start(2020-06-28 10:57:48.197143): patientdetail\n",
      "End(2020-06-28 10:57:55.226869): patientdetail\n",
      "Start(2020-06-28 10:57:55.226869): Concrete_Data\n",
      "End(2020-06-28 10:58:08.162094): Concrete_Data\n",
      "Start(2020-06-28 10:58:08.162094): review\n",
      "End(2020-06-28 10:58:17.283656): review\n",
      "Start(2020-06-28 10:58:17.283656): Titanic\n",
      "End(2020-06-28 10:58:40.959175): Titanic\n",
      "Start(2020-06-28 10:58:40.959175): StorageAnalysistest\n",
      "End(2020-06-28 10:58:51.433947): StorageAnalysistest\n",
      "Start(2020-06-28 10:58:51.433947): earthquake\n",
      "End(2020-06-28 10:59:07.847082): earthquake\n",
      "Start(2020-06-28 10:59:07.847082): core_dataset\n",
      "End(2020-06-28 10:59:16.125350): core_dataset\n",
      "Start(2020-06-28 10:59:16.126352): food_coded\n",
      "End(2020-06-28 10:59:53.047860): food_coded\n",
      "Start(2020-06-28 10:59:53.047860): HR_Full\n",
      "End(2020-06-28 11:00:07.258801): HR_Full\n",
      "Start(2020-06-28 11:00:07.259804): patient\n",
      "End(2020-06-28 11:00:18.145636): patient\n",
      "Start(2020-06-28 11:00:18.145636): Rock_Mine\n",
      "End(2020-06-28 11:00:31.561371): Rock_Mine\n",
      "Start(2020-06-28 11:00:31.561371): winequality-red\n",
      "End(2020-06-28 11:01:29.002696): winequality-red\n",
      "Start(2020-06-28 11:01:29.002696): Sacramento_realestate_transactions\n",
      "End(2020-06-28 11:02:04.934755): Sacramento_realestate_transactions\n",
      "Start(2020-06-28 11:02:04.934755): Cancer_Diagnostic\n",
      "End(2020-06-28 11:02:40.308439): Cancer_Diagnostic\n",
      "Start(2020-06-28 11:02:40.309438): Detect_anomaly\n",
      "End(2020-06-28 11:02:45.195436): Detect_anomaly\n",
      "Start(2020-06-28 11:02:45.195436): Curr_test\n",
      "End(2020-06-28 11:03:11.927150): Curr_test\n",
      "Start(2020-06-28 11:03:11.928149): soybean\n",
      "End(2020-06-28 11:07:38.067765): soybean\n",
      "Start(2020-06-28 11:07:38.068767): abalone_data\n",
      "End(2020-06-28 11:08:56.995457): abalone_data\n",
      "Start(2020-06-28 11:08:56.996456): Azdata\n",
      "End(2020-06-28 11:09:29.025744): Azdata\n",
      "Start(2020-06-28 11:09:29.026751): Missing_People\n",
      "End(2020-06-28 11:10:11.364740): Missing_People\n",
      "Start(2020-06-28 11:10:11.364740): test_detect_anoms\n",
      "End(2020-06-28 11:10:24.169286): test_detect_anoms\n",
      "Start(2020-06-28 11:10:24.170287): all\n",
      "End(2020-06-28 12:16:10.485512): all\n",
      "Start(2020-06-28 12:16:10.485512): all\n",
      "End(2020-06-28 12:17:47.082364): all\n",
      "Start(2020-06-28 12:17:47.082364): mushrooms\n",
      "End(2020-06-28 12:19:17.922905): mushrooms\n",
      "Start(2020-06-28 12:19:17.922905): PMS_TS\n",
      "End(2020-06-28 14:50:54.195695): PMS_TS\n",
      "Start(2020-06-28 14:50:54.254701): house\n",
      "End(2020-06-28 14:55:03.545004): house\n",
      "Start(2020-06-28 14:55:03.546001): all_data_ii\n",
      "End(2020-06-28 15:00:08.432458): all_data_ii\n",
      "Start(2020-06-28 15:00:08.433438): HR\n",
      "End(2020-06-28 15:08:41.302238): HR\n",
      "Start(2020-06-28 15:08:41.302238): Mart_Sales\n",
      "End(2020-06-28 15:09:23.899457): Mart_Sales\n",
      "Start(2020-06-28 15:09:23.900436): CC_GENERAL\n",
      "End(2020-06-28 15:14:46.161038): CC_GENERAL\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Size(MB)</th>\n",
       "      <th>#_Rows</th>\n",
       "      <th>#_Columns</th>\n",
       "      <th>#_Category_cols</th>\n",
       "      <th>#_Numerical_cols</th>\n",
       "      <th>#_Missing_values</th>\n",
       "      <th>Target_col</th>\n",
       "      <th>Target_dtype</th>\n",
       "      <th>#_Target_Unique_values</th>\n",
       "      <th>Model_type</th>\n",
       "      <th>ExecTime_RandomForest</th>\n",
       "      <th>ExecTime_XGBoost</th>\n",
       "      <th>ExecTime_LightGBM</th>\n",
       "      <th>str_ExecTime_RF</th>\n",
       "      <th>str_ExecTime_XGB</th>\n",
       "      <th>str_ExecTime_LGB</th>\n",
       "      <th>str_ET_RF</th>\n",
       "      <th>str_ET_XGB</th>\n",
       "      <th>str_ET_LGB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NAN_file</td>\n",
       "      <td>0.006883</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>diagnosis</td>\n",
       "      <td>object</td>\n",
       "      <td>2</td>\n",
       "      <td>Binary Classification</td>\n",
       "      <td>00:00:00.948802</td>\n",
       "      <td>00:00:00.439981</td>\n",
       "      <td>00:00:00.079974</td>\n",
       "      <td>0:00:00.948802</td>\n",
       "      <td>0:00:00.439981</td>\n",
       "      <td>0:00:00.079974</td>\n",
       "      <td>0 days 00:00:00.948802</td>\n",
       "      <td>0 days 00:00:00.439981</td>\n",
       "      <td>0 days 00:00:00.079974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>recruiting_costs</td>\n",
       "      <td>0.003888</td>\n",
       "      <td>22</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Total</td>\n",
       "      <td>int64</td>\n",
       "      <td>15</td>\n",
       "      <td>Regression</td>\n",
       "      <td>00:00:03.798507</td>\n",
       "      <td>00:00:00.518079</td>\n",
       "      <td>00:00:00.071993</td>\n",
       "      <td>0:00:03.798507</td>\n",
       "      <td>0:00:00.518079</td>\n",
       "      <td>0:00:00.071993</td>\n",
       "      <td>0 days 00:00:03.798507</td>\n",
       "      <td>0 days 00:00:00.518079</td>\n",
       "      <td>0 days 00:00:00.071993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>recruiting_costs</td>\n",
       "      <td>0.003888</td>\n",
       "      <td>22</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Employment Source</td>\n",
       "      <td>object</td>\n",
       "      <td>22</td>\n",
       "      <td>Multiclass Classification</td>\n",
       "      <td>00:00:00.423982</td>\n",
       "      <td>00:00:00.809958</td>\n",
       "      <td>00:00:00.132092</td>\n",
       "      <td>0:00:00.423982</td>\n",
       "      <td>0:00:00.809958</td>\n",
       "      <td>0:00:00.132092</td>\n",
       "      <td>0 days 00:00:00.423982</td>\n",
       "      <td>0 days 00:00:00.809958</td>\n",
       "      <td>0 days 00:00:00.132092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fertility_Diagnosis</td>\n",
       "      <td>0.012924</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>target</td>\n",
       "      <td>object</td>\n",
       "      <td>2</td>\n",
       "      <td>Binary Classification</td>\n",
       "      <td>00:00:02.168140</td>\n",
       "      <td>00:00:00.463959</td>\n",
       "      <td>00:00:01.628931</td>\n",
       "      <td>0:00:02.168140</td>\n",
       "      <td>0:00:00.463959</td>\n",
       "      <td>0:00:01.628931</td>\n",
       "      <td>0 days 00:00:02.168140</td>\n",
       "      <td>0 days 00:00:00.463959</td>\n",
       "      <td>0 days 00:00:01.628931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>headbrain</td>\n",
       "      <td>0.007378</td>\n",
       "      <td>237</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Brain Weight(grams)</td>\n",
       "      <td>int64</td>\n",
       "      <td>146</td>\n",
       "      <td>Regression</td>\n",
       "      <td>00:00:00.329002</td>\n",
       "      <td>00:00:00.087993</td>\n",
       "      <td>00:00:00.127968</td>\n",
       "      <td>0:00:00.329002</td>\n",
       "      <td>0:00:00.087993</td>\n",
       "      <td>0:00:00.127968</td>\n",
       "      <td>0 days 00:00:00.329002</td>\n",
       "      <td>0 days 00:00:00.087993</td>\n",
       "      <td>0 days 00:00:00.127968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Dataset  Size(MB)  #_Rows  #_Columns  #_Category_cols  \\\n",
       "0             NAN_file  0.006883      17         11               10   \n",
       "1     recruiting_costs  0.003888      22         14               14   \n",
       "2     recruiting_costs  0.003888      22         14               14   \n",
       "3  fertility_Diagnosis  0.012924     100         10                5   \n",
       "4            headbrain  0.007378     237          4                4   \n",
       "\n",
       "   #_Numerical_cols  #_Missing_values           Target_col Target_dtype  \\\n",
       "0                 1                 0            diagnosis       object   \n",
       "1                 0                 0                Total        int64   \n",
       "2                 0                 0    Employment Source       object   \n",
       "3                 5                 0               target       object   \n",
       "4                 0                 0  Brain Weight(grams)        int64   \n",
       "\n",
       "   #_Target_Unique_values                 Model_type ExecTime_RandomForest  \\\n",
       "0                       2      Binary Classification       00:00:00.948802   \n",
       "1                      15                 Regression       00:00:03.798507   \n",
       "2                      22  Multiclass Classification       00:00:00.423982   \n",
       "3                       2      Binary Classification       00:00:02.168140   \n",
       "4                     146                 Regression       00:00:00.329002   \n",
       "\n",
       "  ExecTime_XGBoost ExecTime_LightGBM str_ExecTime_RF str_ExecTime_XGB  \\\n",
       "0  00:00:00.439981   00:00:00.079974  0:00:00.948802   0:00:00.439981   \n",
       "1  00:00:00.518079   00:00:00.071993  0:00:03.798507   0:00:00.518079   \n",
       "2  00:00:00.809958   00:00:00.132092  0:00:00.423982   0:00:00.809958   \n",
       "3  00:00:00.463959   00:00:01.628931  0:00:02.168140   0:00:00.463959   \n",
       "4  00:00:00.087993   00:00:00.127968  0:00:00.329002   0:00:00.087993   \n",
       "\n",
       "  str_ExecTime_LGB               str_ET_RF              str_ET_XGB  \\\n",
       "0   0:00:00.079974  0 days 00:00:00.948802  0 days 00:00:00.439981   \n",
       "1   0:00:00.071993  0 days 00:00:03.798507  0 days 00:00:00.518079   \n",
       "2   0:00:00.132092  0 days 00:00:00.423982  0 days 00:00:00.809958   \n",
       "3   0:00:01.628931  0 days 00:00:02.168140  0 days 00:00:00.463959   \n",
       "4   0:00:00.127968  0 days 00:00:00.329002  0 days 00:00:00.087993   \n",
       "\n",
       "               str_ET_LGB  \n",
       "0  0 days 00:00:00.079974  \n",
       "1  0 days 00:00:00.071993  \n",
       "2  0 days 00:00:00.132092  \n",
       "3  0 days 00:00:01.628931  \n",
       "4  0 days 00:00:00.127968  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stats_below_1000KB = feature_engineering_test(folder_path=folder_path, csv_file_names=csv_below_1000KB)\n",
    "df_stats_below_1000KB['str_ET_RF'] = df_stats_below_1000KB['ExecTime_RandomForest'].apply(lambda x: str(x) if x!=None else x)\n",
    "df_stats_below_1000KB['str_ET_XGB'] = df_stats_below_1000KB['ExecTime_XGBoost'].apply(lambda x: str(x) if x!=None else x)\n",
    "df_stats_below_1000KB['str_ET_LGB'] = df_stats_below_1000KB['ExecTime_LightGBM'].apply(lambda x: str(x) if x!=None else x)\n",
    "df_stats_below_1000KB.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-28T09:47:18.410388Z",
     "start_time": "2020-06-28T09:47:18.074373Z"
    }
   },
   "outputs": [],
   "source": [
    "with pd.ExcelWriter('FeatureEngineering_output_stats.xlsx', engine='openpyxl', mode='a') as writer:\n",
    "    df_stats_below_1000KB.to_excel(writer, sheet_name='(v2)below_1000KB', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T02:18:50.062133Z",
     "start_time": "2020-06-29T02:18:49.658090Z"
    }
   },
   "outputs": [],
   "source": [
    "folder_path = \"D:/Solverminds/Datasets/\"\n",
    "csv_1000KB_to_10000KB_1 = [('Nursery_Trn','Class'),('traintop20022','target'),('injury_incident_nearmiss','vessel'),\n",
    "                         ('video_games_sales','Rating'),('Bay_Data','bay1'),('OWT','c1'),('netflix_titles_nov_2019','rating'),\n",
    "                         ('bank-full','y'),('Adult_data_Set','income'),('Adult_data_Set','maritalstatus'),('Banking','y'),\n",
    "                         ('tmdb_5000_movies','vote_average'),('consolidated_coin_data','Market Cap'),\n",
    "                         ('Sepsis','Death')]\n",
    "\n",
    "\n",
    "csv_1000KB_to_10000KB_2 = [('consolidated_coin_data','Market Cap'),('Sepsis','Death')]\n",
    "\n",
    "csv_1000KB_to_10000KB_3 = [('Sepsis','Death')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T02:42:49.773254Z",
     "start_time": "2020-06-29T02:20:31.570036Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start(2020-06-29 07:50:32.705910): Sepsis\n",
      "End(2020-06-29 08:12:49.397277): Sepsis\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Size(MB)</th>\n",
       "      <th>#_Rows</th>\n",
       "      <th>#_Columns</th>\n",
       "      <th>#_Category_cols</th>\n",
       "      <th>#_Numerical_cols</th>\n",
       "      <th>#_Missing_values</th>\n",
       "      <th>Target_col</th>\n",
       "      <th>Target_dtype</th>\n",
       "      <th>#_Target_Unique_values</th>\n",
       "      <th>Model_type</th>\n",
       "      <th>ExecTime_RandomForest</th>\n",
       "      <th>ExecTime_XGBoost</th>\n",
       "      <th>ExecTime_LightGBM</th>\n",
       "      <th>str_ExecTime_RF</th>\n",
       "      <th>str_ExecTime_XGB</th>\n",
       "      <th>str_ExecTime_LGB</th>\n",
       "      <th>str_ET_RF</th>\n",
       "      <th>str_ET_XGB</th>\n",
       "      <th>str_ET_LGB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sepsis</td>\n",
       "      <td>47.82975</td>\n",
       "      <td>44677</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>10162</td>\n",
       "      <td>Death</td>\n",
       "      <td>int64</td>\n",
       "      <td>2</td>\n",
       "      <td>Regression</td>\n",
       "      <td>00:12:08.312042</td>\n",
       "      <td>00:09:36.937196</td>\n",
       "      <td>00:00:21.097224</td>\n",
       "      <td>0:12:08.312042</td>\n",
       "      <td>0:09:36.937196</td>\n",
       "      <td>0:00:21.097224</td>\n",
       "      <td>0 days 00:12:08.312042</td>\n",
       "      <td>0 days 00:09:36.937196</td>\n",
       "      <td>0 days 00:00:21.097224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dataset  Size(MB)  #_Rows  #_Columns  #_Category_cols  #_Numerical_cols  \\\n",
       "0  Sepsis  47.82975   44677         76               76                 0   \n",
       "\n",
       "   #_Missing_values Target_col Target_dtype  #_Target_Unique_values  \\\n",
       "0             10162      Death        int64                       2   \n",
       "\n",
       "   Model_type ExecTime_RandomForest ExecTime_XGBoost ExecTime_LightGBM  \\\n",
       "0  Regression       00:12:08.312042  00:09:36.937196   00:00:21.097224   \n",
       "\n",
       "  str_ExecTime_RF str_ExecTime_XGB str_ExecTime_LGB               str_ET_RF  \\\n",
       "0  0:12:08.312042   0:09:36.937196   0:00:21.097224  0 days 00:12:08.312042   \n",
       "\n",
       "               str_ET_XGB              str_ET_LGB  \n",
       "0  0 days 00:09:36.937196  0 days 00:00:21.097224  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stats_1000KB_to_10000KB = feature_engineering_test(folder_path=folder_path, csv_file_names=csv_1000KB_to_10000KB_3)\n",
    "df_stats_1000KB_to_10000KB.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T06:22:56.867845Z",
     "start_time": "2020-06-29T06:22:56.651330Z"
    }
   },
   "outputs": [],
   "source": [
    "folder_path = \"D:/Solverminds/Datasets/\"\n",
    "csv_10000KB_to_50000KB_1 = [('nyc-rolling-sales-2','SALE PRICE'),('fifa_data','special'),('insurance_data','Response'),\n",
    "                          ('HES_DATA_1','classpat'),('Date_data_check','weight'),('athlete_events','Medal')]\n",
    "csv_10000KB_to_50000KB_2 = [('fifa_data','special'),('insurance_data','Response'),\n",
    "                          ('HES_DATA_1','classpat'),('Date_data_check','weight'),('athlete_events','Medal')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T15:44:44.085498Z",
     "start_time": "2020-06-29T06:23:10.956138Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start(2020-06-29 11:53:12.013083): fifa_data\n",
      "End(2020-06-29 15:02:34.305867): fifa_data\n",
      "Start(2020-06-29 15:02:34.315594): insurance_data\n",
      "End(2020-06-29 16:55:43.281106): insurance_data\n",
      "Start(2020-06-29 16:55:43.418622): HES_DATA_1\n",
      "End(2020-06-29 19:16:52.031412): HES_DATA_1\n",
      "Start(2020-06-29 19:16:52.033411): Date_data_check\n",
      "End(2020-06-29 19:40:30.070561): Date_data_check\n",
      "Start(2020-06-29 19:40:30.070561): athlete_events\n",
      "End(2020-06-29 21:14:42.754998): athlete_events\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Size(MB)</th>\n",
       "      <th>#_Rows</th>\n",
       "      <th>#_Columns</th>\n",
       "      <th>#_Category_cols</th>\n",
       "      <th>#_Numerical_cols</th>\n",
       "      <th>#_Missing_values</th>\n",
       "      <th>Target_col</th>\n",
       "      <th>Target_dtype</th>\n",
       "      <th>#_Target_Unique_values</th>\n",
       "      <th>Model_type</th>\n",
       "      <th>ExecTime_RandomForest</th>\n",
       "      <th>ExecTime_XGBoost</th>\n",
       "      <th>ExecTime_LightGBM</th>\n",
       "      <th>str_ExecTime_RF</th>\n",
       "      <th>str_ExecTime_XGB</th>\n",
       "      <th>str_ExecTime_LGB</th>\n",
       "      <th>str_ET_RF</th>\n",
       "      <th>str_ET_XGB</th>\n",
       "      <th>str_ET_LGB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fifa_data</td>\n",
       "      <td>29.305033</td>\n",
       "      <td>17994</td>\n",
       "      <td>185</td>\n",
       "      <td>185</td>\n",
       "      <td>0</td>\n",
       "      <td>70772</td>\n",
       "      <td>special</td>\n",
       "      <td>int64</td>\n",
       "      <td>1394</td>\n",
       "      <td>Regression</td>\n",
       "      <td>02:28:04.575302</td>\n",
       "      <td>00:37:03.703098</td>\n",
       "      <td>00:04:04.456138</td>\n",
       "      <td>2:28:04.575302</td>\n",
       "      <td>0:37:03.703098</td>\n",
       "      <td>0:04:04.456138</td>\n",
       "      <td>0 days 02:28:04.575302</td>\n",
       "      <td>0 days 00:37:03.703098</td>\n",
       "      <td>0 days 00:04:04.456138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>insurance_data</td>\n",
       "      <td>60.877540</td>\n",
       "      <td>59381</td>\n",
       "      <td>128</td>\n",
       "      <td>19</td>\n",
       "      <td>109</td>\n",
       "      <td>393103</td>\n",
       "      <td>Response</td>\n",
       "      <td>int64</td>\n",
       "      <td>8</td>\n",
       "      <td>Regression</td>\n",
       "      <td>00:45:43.451490</td>\n",
       "      <td>01:05:47.604491</td>\n",
       "      <td>00:01:30.691619</td>\n",
       "      <td>0:45:43.451490</td>\n",
       "      <td>1:05:47.604491</td>\n",
       "      <td>0:01:30.691619</td>\n",
       "      <td>0 days 00:45:43.451490</td>\n",
       "      <td>0 days 01:05:47.604491</td>\n",
       "      <td>0 days 00:01:30.691619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HES_DATA_1</td>\n",
       "      <td>324.552448</td>\n",
       "      <td>324235</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>2095945</td>\n",
       "      <td>classpat</td>\n",
       "      <td>float64</td>\n",
       "      <td>4</td>\n",
       "      <td>Regression</td>\n",
       "      <td>00:21:57.640027</td>\n",
       "      <td>01:53:10.733750</td>\n",
       "      <td>00:05:46.233401</td>\n",
       "      <td>0:21:57.640027</td>\n",
       "      <td>1:53:10.733750</td>\n",
       "      <td>0:05:46.233401</td>\n",
       "      <td>0 days 00:21:57.640027</td>\n",
       "      <td>0 days 01:53:10.733750</td>\n",
       "      <td>0 days 00:05:46.233401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Date_data_check</td>\n",
       "      <td>182.748485</td>\n",
       "      <td>394531</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>weight</td>\n",
       "      <td>float64</td>\n",
       "      <td>70802</td>\n",
       "      <td>Regression</td>\n",
       "      <td>00:14:04.623742</td>\n",
       "      <td>00:06:49.061185</td>\n",
       "      <td>00:02:39.390138</td>\n",
       "      <td>0:14:04.623742</td>\n",
       "      <td>0:06:49.061185</td>\n",
       "      <td>0:02:39.390138</td>\n",
       "      <td>0 days 00:14:04.623742</td>\n",
       "      <td>0 days 00:06:49.061185</td>\n",
       "      <td>0 days 00:02:39.390138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>athlete_events</td>\n",
       "      <td>178.806782</td>\n",
       "      <td>271116</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>363853</td>\n",
       "      <td>Medal</td>\n",
       "      <td>object</td>\n",
       "      <td>3</td>\n",
       "      <td>Multiclass Classification</td>\n",
       "      <td>00:07:36.529535</td>\n",
       "      <td>01:25:05.985313</td>\n",
       "      <td>00:01:24.655466</td>\n",
       "      <td>0:07:36.529535</td>\n",
       "      <td>1:25:05.985313</td>\n",
       "      <td>0:01:24.655466</td>\n",
       "      <td>0 days 00:07:36.529535</td>\n",
       "      <td>0 days 01:25:05.985313</td>\n",
       "      <td>0 days 00:01:24.655466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Dataset    Size(MB)  #_Rows  #_Columns  #_Category_cols  \\\n",
       "0        fifa_data   29.305033   17994        185              185   \n",
       "1   insurance_data   60.877540   59381        128               19   \n",
       "2       HES_DATA_1  324.552448  324235         24               23   \n",
       "3  Date_data_check  182.748485  394531         11                8   \n",
       "4   athlete_events  178.806782  271116         15               13   \n",
       "\n",
       "   #_Numerical_cols  #_Missing_values Target_col Target_dtype  \\\n",
       "0                 0             70772    special        int64   \n",
       "1               109            393103   Response        int64   \n",
       "2                 1           2095945   classpat      float64   \n",
       "3                 3                 7     weight      float64   \n",
       "4                 2            363853      Medal       object   \n",
       "\n",
       "   #_Target_Unique_values                 Model_type ExecTime_RandomForest  \\\n",
       "0                    1394                 Regression       02:28:04.575302   \n",
       "1                       8                 Regression       00:45:43.451490   \n",
       "2                       4                 Regression       00:21:57.640027   \n",
       "3                   70802                 Regression       00:14:04.623742   \n",
       "4                       3  Multiclass Classification       00:07:36.529535   \n",
       "\n",
       "  ExecTime_XGBoost ExecTime_LightGBM str_ExecTime_RF str_ExecTime_XGB  \\\n",
       "0  00:37:03.703098   00:04:04.456138  2:28:04.575302   0:37:03.703098   \n",
       "1  01:05:47.604491   00:01:30.691619  0:45:43.451490   1:05:47.604491   \n",
       "2  01:53:10.733750   00:05:46.233401  0:21:57.640027   1:53:10.733750   \n",
       "3  00:06:49.061185   00:02:39.390138  0:14:04.623742   0:06:49.061185   \n",
       "4  01:25:05.985313   00:01:24.655466  0:07:36.529535   1:25:05.985313   \n",
       "\n",
       "  str_ExecTime_LGB               str_ET_RF              str_ET_XGB  \\\n",
       "0   0:04:04.456138  0 days 02:28:04.575302  0 days 00:37:03.703098   \n",
       "1   0:01:30.691619  0 days 00:45:43.451490  0 days 01:05:47.604491   \n",
       "2   0:05:46.233401  0 days 00:21:57.640027  0 days 01:53:10.733750   \n",
       "3   0:02:39.390138  0 days 00:14:04.623742  0 days 00:06:49.061185   \n",
       "4   0:01:24.655466  0 days 00:07:36.529535  0 days 01:25:05.985313   \n",
       "\n",
       "               str_ET_LGB  \n",
       "0  0 days 00:04:04.456138  \n",
       "1  0 days 00:01:30.691619  \n",
       "2  0 days 00:05:46.233401  \n",
       "3  0 days 00:02:39.390138  \n",
       "4  0 days 00:01:24.655466  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stats_10000KB_to_50000KB = feature_engineering_test(folder_path=folder_path, csv_file_names=csv_10000KB_to_50000KB_2)\n",
    "df_stats_10000KB_to_50000KB.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T16:19:36.030167Z",
     "start_time": "2020-06-29T16:19:35.822245Z"
    }
   },
   "outputs": [],
   "source": [
    "folder_path = \"D:/Solverminds/Datasets/\"\n",
    "csv_50000KB_to_150000KB = [('Electricity_P','UNE'),('resources','price'),('creditcard','Amount')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-06-29T16:19:39.226Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start(2020-06-29 21:49:41.115116): Electricity_P\n"
     ]
    }
   ],
   "source": [
    "df_stats_50000KB_to_150000KB = feature_engineering_test(folder_path=folder_path, csv_file_names=csv_50000KB_to_150000KB)\n",
    "df_stats_50000KB_to_150000KB.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
